import os
import streamlit as st
import tempfile
import time
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain_community.document_loaders import UnstructuredWordDocumentLoader, TextLoader

# ✅ 设置 OpenAI API Key
OPENAI_API_KEY = "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"
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

# ✅ **Streamlit 页面配置**
st.set_page_config(page_title="🚀 Full-Powered GPT", layout="wide")

# ✅ **添加动图背景**
st.markdown("""
    <style>
    .stApp {
        background: url("https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExYWNzcDE2amJlMXNkNm85amV6azhqN3JiNG16M2g4aHExbmZ2dnFoeSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/7VzgMsB6FLCilwS30v/giphy.gif") no-repeat center center fixed;
        background-size: cover;
    } 
    </style>
""", unsafe_allow_html=True)

st.markdown("""
    <style>
        /* 修改标题颜色 */
        .stApp h1 {
            color: #FFD700 !important;  /* 标题变成金色 */
            text-align: center !important;
        }

        /* 修改上传文件的标题 */
        .stFileUploader label {
            color: #FFFFFF !important;  /* 亮紫色 */
            font-size: 16px !important;
            font-weight: bold !important;
        }

        /* 修改已上传的文件名颜色 */
        .uploadedFile {
            color: #FFFFFF !important;  /* 深灰色 */
            font-size: 14px !important;
            font-weight: bold !important;
        }
         /* 用户提问气泡 */
        .stChatMessageUser {
            background-color: #3b5998 !important;  /* 淡蓝色 */
            color: #FFFFFF !important;  /* 纯白字体 */
            font-weight: bold !important;
            font-size: 16px !important;
            padding: 12px !important;
            border-radius: 10px !important;
            box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.2) !important;
        }

        /* AI 回复气泡 */
        .stChatMessageAssistant {
            background-color: #FFFFFF !important;  /* 纯白背景 */
            color: #000000 !important;  /* 黑色字体 */
            font-weight: bold !important;
            font-size: 16px !important;
            padding: 12px !important;
            border-radius: 10px !important;
            box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.2) !important;
        }
    </style>
    """, unsafe_allow_html=True)

st.markdown("""
    <style>
        /* 修改提示信息 (st.info) 的颜色 */
        .stAlert {
            color: #FFFFFF !important;  /* 文字变成白色 */
            font-weight: bold !important;
            font-size: 16px !important;
        }
    </style>
""", unsafe_allow_html=True)
st.markdown(
    """
    <style>
        /* 修改上传后文件名的颜色 */
        .stUploadedFile {
            color: #FFFFFF !important;  /* 这里改成你想要的颜色，比如白色 */
            font-size: 14px !important;
            font-weight: bold !important;
        }
    </style>
    """,
    unsafe_allow_html=True
)

# ✅ **标题**
st.title("💬 Chat with Documents")

# ✅ **文件上传**
uploaded_files = st.file_uploader("📂 Upload documents (PDF, DOCX, TXT)", accept_multiple_files=True, type=["pdf", "docx", "txt"])

if uploaded_files:
    documents = []

    # ✅ **初始化向量存储**
    if "vector_store" not in st.session_state:
        with st.spinner("🔄 Processing your documents..."):
            with tempfile.TemporaryDirectory() as temp_dir:
                for file in uploaded_files:
                    temp_file_path = os.path.join(temp_dir, file.name)
                    with open(temp_file_path, "wb") as f:
                        f.write(file.getbuffer())

                    # 选择加载器
                    if file.name.endswith(".pdf"):
                        loader = PyPDFLoader(temp_file_path)
                    elif file.name.endswith(".docx"):
                        loader = UnstructuredWordDocumentLoader(temp_file_path)
                    elif file.name.endswith(".txt"):
                        loader = TextLoader(temp_file_path)
                    else:
                        continue

                    documents.extend(loader.load())

                # **文本分块**
                text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
                docs = text_splitter.split_documents(documents)

                # **生成嵌入并存入 FAISS**
                embeddings = OpenAIEmbeddings()
                st.session_state.vector_store = FAISS.from_documents(docs, embeddings)

        st.success("✅ Documents processed! You can start chatting.")

    # ✅ **初始化聊天记录**
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ✅ **显示聊天历史**
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ✅ **用户输入**
    user_input = st.chat_input("💬 Ask a question about your documents...")

    if user_input:
        # 🎤 **添加用户消息**
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        # 🔗 **创建对话链**
        memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
        retriever = st.session_state.vector_store.as_retriever()
        
        qa_chain = ConversationalRetrievalChain.from_llm(
            llm=ChatOpenAI(model_name="gpt-4o", temperature=0.2, max_tokens=512),
            retriever=retriever,
            memory=memory
        )

        # 🤖 **生成回答**
        with st.spinner("🤖 Thinking..."):
            response = qa_chain.invoke({"question": user_input})
            response_text = response["answer"]

         # ⏳ **流式显示 AI 响应**
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            for chunk in response_text:
                full_response += chunk
                message_placeholder.markdown(full_response + "▌")
                time.sleep(0.05)
            message_placeholder.markdown(full_response)

        # 💾 **保存消息记录**
        st.session_state.messages.append({"role": "assistant", "content": response_text})
